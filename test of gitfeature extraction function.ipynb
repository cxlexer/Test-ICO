{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import requests, ConnectionError, \n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from operator import itemgetter \n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DATA_FILEPATH = '/users/eric/PycharmProjects/testico/api_data.json'\n",
    "URL_FILEPATH = '/users/eric/PycharmProjects/testico/ico_urls.txt'\n",
    "TOKEN_FILE = '/users/eric/PycharmProjects/testico/token.csv'\n",
    "FULLDATA_FILE = '/users/eric/PycharmProjects/testico/fulldata.csv'\n",
    "NUMERICAL_DATA_FILE = '/users/eric/PycharmProjects/testico/full_num.csv'\n",
    "TEXT_DATA_FILE = '/users/eric/PycharmProjects/testico/textfeature_dataframe.csv'\n",
    "URL_COPY_FILEPATH = '/users/eric/PycharmProjects/testico/ico_urls copy.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repolink_extract(url):\n",
    "    try:\n",
    "        html = requests.get(url)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(url)\n",
    "        return None\n",
    "    htmltxt = bs(html.text, 'html.parser')\n",
    "    \n",
    "    \n",
    "    repohtml = htmltxt.find_all('a', class_=\"d-inline-block\", \n",
    "                                itemprop=\"name codeRepository\")\n",
    "\n",
    "    partial_repolink_list = []\n",
    "    for item in repohtml:\n",
    "        link = item.attrs['href']\n",
    "        partial_repolink_list.append(link)\n",
    "    return partial_repolink_list\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "def nextpage_extract(url):\n",
    "    try:\n",
    "        html = requests.get(url)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(url)\n",
    "        return None\n",
    "    htmltxt = bs(html.text, 'html.parser')\n",
    "\n",
    "    nextpage = htmltxt.find_all('a', \n",
    "                    class_=\"next_page\",\n",
    "                    rel=\"next\")\n",
    "    if len(nextpage) != 0:\n",
    "        a = 'https://github.com'\n",
    "        next_ = nextpage[0].attrs['href']\n",
    "        nextlink = '{}{}'.format(a, next_)\n",
    "        return nextlink\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def repolink_extract_paginator(current_url):\n",
    "    output = repolink_extract(current_url)\n",
    "    next_url = nextpage_extract(current_url)\n",
    "    while next_url is not None:\n",
    "        current_url = next_url\n",
    "        output_temp = repolink_extract(current_url)\n",
    "        output.append(output_temp)\n",
    "        next_url = nextpage_extract(current_url)\n",
    "        time.sleep(1)\n",
    "    repolink_list = []\n",
    "    def reemoveNestings(l):\n",
    "        for i in l:\n",
    "            if type(i) == list:\n",
    "                reemoveNestings(i)\n",
    "            else:\n",
    "                repolink_list.append(i)\n",
    "    reemoveNestings(output)\n",
    "    \n",
    "    return repolink_list\n",
    "\n",
    "def gitfeature_extract(partial_repolink):\n",
    "    a = 'https://github.com'\n",
    "    full_repolink = '{}{}'.format(a, partial_repolink)\n",
    "    try:\n",
    "        githtml = requests.get(full_repolink)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(partial_repolink)\n",
    "        gitfeature = {\n",
    "            'watchers':0,\n",
    "            'stars': 0,\n",
    "            'forks':0, \n",
    "            'commits':0,\n",
    "            'branches':0}\n",
    "        return gitfeature\n",
    "    githtmltxt = bs(githtml.text, 'html.parser')\n",
    "    otherfeature_html = githtmltxt.find_all(\n",
    "       'span', class_=\"num text-emphasized\")\n",
    "    if len(otherfeature_html) == 0:\n",
    "        gitfeature = {\n",
    "            'watchers':0,\n",
    "            'stars': 0,\n",
    "            'forks':0, \n",
    "            'commits':0,\n",
    "            'branches':0}\n",
    "        return gitfeature\n",
    "    else:\n",
    "        watch_html = githtmltxt.find_all(\n",
    "            'a', \n",
    "            class_=\"social-count\",\n",
    "            href= '{}{}'.format(partial_repolink,'/watchers')\n",
    "        )\n",
    "        watch = watch_html[0].text.strip().replace(',', '')\n",
    "        stars_html = githtmltxt.find_all(\n",
    "            'a',\n",
    "            class_=\"social-count\",\n",
    "            href= '{}{}'.format(partial_repolink,'/stargazers')\n",
    "        )\n",
    "        stars = stars_html[0].text.strip().replace(',', '')\n",
    "        forks_html = githtmltxt.find_all(\n",
    "            'a',\n",
    "            href= '{}{}'.format(partial_repolink,'/network/members'),\n",
    "            class_=\"social-count\"\n",
    "        )\n",
    "\n",
    "        forks = forks_html[0].text.strip().replace(',', '')\n",
    "\n",
    "        otherfeature_html = githtmltxt.find_all(\n",
    "           'span', class_=\"num text-emphasized\")\n",
    "        commits = otherfeature_html[0].text.strip().replace(',', '')\n",
    "        branches = otherfeature_html[1].text.strip().replace(',', '')\n",
    "        releases = otherfeature_html[2].text.strip().replace(',', '')\n",
    "        gitfeature = {\n",
    "            'watchers':watch,\n",
    "            'stars': stars,\n",
    "            'forks':forks, \n",
    "            'commits':commits,\n",
    "            'branches':branches}\n",
    "        return gitfeature\n",
    "\n",
    "def repofeature_extract_paginator(current_url):\n",
    "    output = repolink_extract(current_url)\n",
    "    next_url = nextpage_extract(current_url)\n",
    "    while next_url is not None:\n",
    "        current_url = next_url\n",
    "        output_temp = repolink_extract(current_url)\n",
    "        output.append(output_temp)\n",
    "        next_url = nextpage_extract(current_url)\n",
    "        time.sleep(1)\n",
    "    repolink_list = []\n",
    "    def reemoveNestings(l):\n",
    "        for i in l:\n",
    "            if type(i) == list:\n",
    "                reemoveNestings(i)\n",
    "            else:\n",
    "                repolink_list.append(i)\n",
    "    reemoveNestings(output)\n",
    "    d_list = []\n",
    "    feature_sum = {}\n",
    "    for partial_repolink in repolink_list:\n",
    "        feature_dic = gitfeature_extract(partial_repolink)\n",
    "        d_list.append(feature_dic)\n",
    "    for d in d_list:\n",
    "        for k in d.keys():\n",
    "            feature_sum[k] = feature_sum.get(k, 0) + int((d[k]))\n",
    "    return feature_sum\n",
    "\n",
    "def gitfeature_html(github_account_html):\n",
    "    if github_account_html is None:\n",
    "        gitfeature = {\n",
    "            'watchers':0,\n",
    "            'stars': 0,\n",
    "            'forks':0, \n",
    "            'commits':0,\n",
    "            'branches':0}\n",
    "        return gitfeature\n",
    "    else:\n",
    "        try:\n",
    "            html = requests.get(github_account_html)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(url)\n",
    "            gitfeature ={\n",
    "            'watchers':0,\n",
    "            'stars': 0,\n",
    "            'forks':0, \n",
    "            'commits':0,\n",
    "            'branches':0}\n",
    "            return gitfeature\n",
    "        htmltxt = bs(html.text, 'html.parser')\n",
    "        repohtml = htmltxt.find_all('a',class_=\"d-inline-block\", \n",
    "                                    itemprop=\"name codeRepository\")\n",
    "        if len(repohtml) == 0:\n",
    "            output = gitfeature_extract(github_account_html.replace('https://github.com', ''))\n",
    "            return output\n",
    "\n",
    "\n",
    "        else:\n",
    "            output = repofeature_extract_paginator(github_account_html)\n",
    "            return output\n",
    "        \n",
    "def get_webpage_link(html_body):\n",
    "\n",
    "    html = html_body.find_all(\"div\", class_=\"col-xs-6 col-md-6\")\n",
    "    if len(html) == 0:\n",
    "        return None\n",
    "    html2 = html[1]\n",
    "    html3 = html2.contents\n",
    "    website = [ii for ii in html3 if not ii == '\\n'][0]\n",
    "    weblink = website.get('href')\n",
    "    return weblink\n",
    "\n",
    "\n",
    "def get_github_link(html_body):\n",
    "\n",
    "    html2 = html_body.find_all(\"div\", class_=\"col-xs-6 col-md-9\")\n",
    "    if len(html2) == 0:\n",
    "        return None\n",
    "    icon = html2[0]\n",
    "    icon1 = icon.contents\n",
    "    link = [item for item in icon1 if not item == '\\n']\n",
    "    linktxt = []\n",
    "    for xx in link:\n",
    "        bb = xx.get('href')\n",
    "        linktxt.append(bb)\n",
    "\n",
    "    for xx in linktxt:\n",
    "        if 'github' in xx:\n",
    "            return xx\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(URL_FILEPATH, 'r') as f:\n",
    "    urls = f.readlines()\n",
    "\n",
    "urls = [url.strip('\\n') for url in urls]\n",
    "results = []\n",
    "for url in urls:\n",
    "    html = requests.get(url)\n",
    "    htmltxt = bs(html.text, 'html.parser')\n",
    "    htmlbody = htmltxt.body\n",
    "    heads = htmlbody.find_all(\"div\", class_=\"col-xs-6 col-md-3\")[2:]\n",
    "    heads = [head.text.strip().split('\\n')[0] for head in heads]\n",
    "    datas = htmlbody.find_all(\"div\", class_=\"col-xs-6 col-md-9\")[2:]\n",
    "    datas = [data.text.strip().split('\\n')[0] for data in datas]\n",
    "    ico_results = list(zip(heads, datas))\n",
    "\n",
    "\n",
    "    github_link = get_github_link(htmlbody)\n",
    "    website_link = get_webpage_link(htmlbody)\n",
    "    ico_results.append(('Github URL', github_link))\n",
    "    ico_results.append(('Official Website', website_link))\n",
    "    results.append(ico_results)\n",
    "    \n",
    "    git_feature = gitfeature_html(github_link)\n",
    "    git_feature_list = []\n",
    "    for key, value in git_feature.items():\n",
    "        temp=(key, value)\n",
    "        git_feature_list.append(temp)\n",
    "        \n",
    "    joinedlist = ico_results + git_feature_list\n",
    "    results.append(joinedlist) \n",
    "    \n",
    "\n",
    "\n",
    "final_results = []\n",
    "for result in results:\n",
    "    dict_result = {key: value for (key, value) in result}\n",
    "    final_results.append(dict_result)\n",
    "\n",
    "for idx, url in enumerate(urls):\n",
    "    name = url.split('/')[-1]\n",
    "    final_results[idx]['name'] = name\n",
    "    final_results[idx]['url'] = url\n",
    "\n",
    "df = pd.DataFrame(final_results)\n",
    "# df.to_csv('token.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid URL '//www.github.com/expa%20%20nse-org': No schema supplied. Perhaps you meant http:////www.github.com/expa%20%20nse-org?\n",
      "https://icowatchlist.com/ico/tokenlab\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'watchers': 0, 'stars': 0, 'forks': 0, 'commits': 0, 'branches': 0}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gitfeature_html('//www.github.com/expa%20%20nse-org')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
